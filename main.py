import os
import tempfile
import streamlit as st
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.chains import LLMMathChain
from langchain.agents import Tool, AgentExecutor, create_tool_calling_agent
from langchain.tools.retriever import create_retriever_tool
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate, PromptTemplate, HumanMessagePromptTemplate
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_community.utilities import WikipediaAPIWrapper
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import PyPDFDirectoryLoader
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

# Thi·∫øt l·∫≠p c√°c bi·∫øn m√¥i tr∆∞·ªùng c·∫ßn thi·∫øt
os.environ['GOOGLE_API_KEY'] = 'GOOGLE_API_KEY'
os.environ['TAVILY_API_KEY'] = 'TAVILY_API_KEY'

# C·∫•u h√¨nh trang Streamlit
st.set_page_config(
    page_title="Chat v·ªõi Gemini & Tools",
    page_icon=":brain:",
    layout="centered",
)

st.header("T·∫£i l√™n t·ªáp th√¥ng tin c·ªßa b·∫°n")

# H√†m chuy·ªÉn ƒë·ªïi vai tr√≤ ng∆∞·ªùi d√πng cho Streamlit
def translate_role_for_streamlit(user_role):
    return "assistant" if user_role == "model" else user_role

# Sidebar ƒë·ªÉ ch·ªçn c√°c c√¥ng c·ª• s·ª≠ d·ª•ng
st.sidebar.title("B·∫°n mu·ªën s·ª≠ d·ª•ng nh·ªØng c√¥ng c·ª• n√†o?")
tools = []

# Kh·ªüi t·∫°o m√¥ h√¨nh LLM
llm = ChatGoogleGenerativeAI(
    model="gemini-1.5-pro",
    temperature=0,
    max_tokens=None,
    timeout=None,
    max_retries=2,
)

# Ti√™u ƒë·ªÅ c·ªßa chatbot tr√™n trang
st.title("ü§ñ Gemini - ChatBot")

# Ph·∫ßn c·∫•u h√¨nh c√¥ng c·ª• t√¨m ki·∫øm d·ª±a tr√™n PDF
retriever_toggle = st.sidebar.checkbox('T√¨m ki·∫øm d·ª±a v√†o pdf t·∫£i l√™n')
if retriever_toggle:
    uploaded_files = st.sidebar.file_uploader("T·∫£i l√™n file PDF c·ªßa b·∫°n", type=['pdf'], accept_multiple_files=True)
    temp_dir = tempfile.mkdtemp()
    topic = st.sidebar.text_input('N·ªôi dung ch√≠nh c·ªßa c√°c file PDF')
    if uploaded_files and st.sidebar.button("X·ª≠ l√≠ t·∫≠p tin PDF", type='primary'):
        for uploaded_file in uploaded_files:
            bytes_data = uploaded_file.read()
            temp_file_path = os.path.join(temp_dir, uploaded_file.name)
            with open(temp_file_path, 'wb') as temp_file:
                temp_file.write(bytes_data)
            st.sidebar.write(f"ƒê√£ x·ª≠ l√≠ xong t·∫≠p tin: {uploaded_file.name}.")
        embeddings = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-small")
        splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        loader = PyPDFDirectoryLoader(path=temp_dir, extract_images=True)
        documents = loader.load_and_split(text_splitter=splitter)
        vector = FAISS.from_documents(documents=documents, embedding=embeddings)
        retriever = vector.as_retriever()
        retriever_tool = create_retriever_tool(
            retriever,
            "docs_search",
            f"Th√¥ng tin li√™n quan ƒë·∫øn ch·ªß ƒë·ªÅ {topic}. ƒê·ªëi v·ªõi b·∫•t k·ª≥ c√¢u h·ªèi n√†o li√™n quan ƒë·∫øn ch·ªß ƒë·ªÅ n√†y, b·∫°n ph·∫£i s·ª≠ d·ª•ng c√¥ng c·ª• n√†y!",
        )
        tools.append(retriever_tool)

# Ph·∫ßn c·∫•u h√¨nh c√¥ng c·ª• t√¨m ki·∫øm tr√™n Wikipedia
wikipedia_toggle = st.sidebar.checkbox('T√¨m ki·∫øm tr√™n Wikipedia')
if wikipedia_toggle:
    wiki = WikipediaAPIWrapper(lang='vi')
    wiki_tool = Tool(
        name="Wikipedia",
        func=wiki.run,
        description="""M·ªôt c√¥ng c·ª• h·ªØu √≠ch ƒë·ªÉ t√¨m ki·∫øm tr√™n internet ƒë·ªÉ t√¨m th√¥ng tin v·ªÅ s·ª± ki·ªán, danh nh√¢n, k·ªâ ni·ªám, ƒë·ªëi t∆∞·ª£ng...
        L∆∞u √Ω: Khi t√¨m ki·∫øm tr√™n Wikipedia h√£y ƒë∆∞a ra nh·ªØng t·ª´ kho√° ch√≠nh trong c√¢u.""",
    )
    tools.append(wiki_tool)

# Ph·∫ßn c·∫•u h√¨nh c√¥ng c·ª• to√°n h·ªçc
math_toggle = st.sidebar.checkbox('C√¥ng c·ª• to√°n h·ªçc')
if math_toggle:
    math_chain = LLMMathChain.from_llm(llm=llm, verbose=True)
    math_tool = Tool.from_function(
        name="Calculator",
        func=math_chain.run,
        description="""M·ªôt c√¥ng c·ª• h·ªØu √≠ch ƒë·ªÉ th·ª±c hi·ªán c√°c ph√©p to√°n h·ªçc
        N·∫øu c√≥ b·∫•t c·ª© c√¢u h·ªèi n√†o v·ªÅ To√°n h·ªçc, b·∫°n ph·∫£i s·ª≠ d·ª•ng c√¥ng c·ª• n√†y!""",
    )
    tools.append(math_tool)

# C√¥ng c·ª• t√¨m ki·∫øm web
web = TavilySearchResults()
web_tool = Tool(
    name="Web",
    func=web.run,
    description="""M·ªôt c√¥ng c·ª• h·ªØu √≠ch ƒë·ªÉ t√¨m ki·∫øm tr√™n internet c√°c ƒë∆∞·ªùng d·∫´n cho ng∆∞·ªùi d√πng tham kh·∫£o th√™m th√¥ng tin.
    L∆∞u √Ω: Khi s·ª≠ d·ª•ng tool ch·ªâ s·ª≠ d·ª•ng t·ª´ kho√° ch√≠nh.
    Khi ƒë∆∞a ra c√¢u tr·∫£ l·ªùi cho c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng, b·∫°n ph·∫£i s·ª≠ d·ª•ng c√¥ng c·ª• n√†y ƒë·ªÉ cung c·∫•p th√™m ƒë∆∞·ªùng d·∫´n tham kh·∫£o cho ng∆∞·ªùi d√πng!""",
)
tools.append(web_tool)

# C·∫•u h√¨nh prompt cho chatbot
prompt = ChatPromptTemplate.from_messages(
    [SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template="""B·∫°n l√† 1 tr·ª£ l√≠ h·ªØu √≠ch ·∫£o v√† b·∫°n c·∫ßn ph·∫£i ƒë∆∞a ra th√¥ng tin ch√≠nh x√°c v√† h·ªØu √≠ch nh·∫•t cho ng∆∞·ªùi s·ª≠ d·ª•ng.
            H√£y ∆∞u ti√™n s·ª≠ d·ª•ng nh·ªØng Tools m√† t√¥i ƒë√£ cung c·∫•p. 
            Khi b·∫°n s·ª≠ d·ª•ng m·ªôt c√¥ng c·ª•, h√£y ƒë·∫£m b·∫£o r·∫±ng b·∫°n cung c·∫•p t√™n c·ªßa c√¥ng c·ª• v√† k·∫øt qu·∫£ c·ªßa n√≥ trong c√¢u tr·∫£ l·ªùi c·ªßa b·∫°n. 
            N·∫øu c√°c c√¥ng c·ª• kh√¥ng h·ªØu √≠ch, h√£y s·ª≠ d·ª•ng ki·∫øn th·ª©c c·ªßa ri√™ng b·∫°n ƒë·ªÉ tr·∫£ l·ªùi.""")),
     MessagesPlaceholder(variable_name='chat_history', optional=True),
     HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),
     MessagesPlaceholder(variable_name='agent_scratchpad'),
    ]
)

# Hi·ªÉn th·ªã th√¥ng b√°o cho ng∆∞·ªùi d√πng
st.info("Vui l√≤ng l√†m m·ªõi tr√¨nh duy·ªát n·∫øu b·∫°n c·∫ßn ƒë·∫∑t l·∫°i phi√™n", icon="üö®")

# T·∫°o agent v√† agent_executor ƒë·ªÉ x·ª≠ l√Ω y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng
agent = create_tool_calling_agent(llm=llm, tools=tools, prompt=prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

# Kh·ªüi t·∫°o l·ªãch s·ª≠ tr√≤ chuy·ªán n·∫øu ch∆∞a c√≥
if "chat_histories" not in st.session_state:
    st.session_state['chat_histories'] = {}

if "messages" not in st.session_state:
    st.session_state.messages = []

# Hi·ªÉn th·ªã c√°c tin nh·∫Øn trong l·ªãch s·ª≠ tr√≤ chuy·ªán khi trang ƒë∆∞·ª£c t·∫£i l·∫°i
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# √î nh·∫≠p li·ªáu cho tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng
if prompt := st.chat_input("C√¢u h·ªèi c·ªßa b·∫°n?"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Truy v·∫•n tr·ª£ l√Ω b·∫±ng l·ªãch s·ª≠ tr√≤ chuy·ªán m·ªõi nh·∫•t
    result = agent_executor.invoke(
        {'input': prompt},
        config={"configurable": {"session_id": "<foo>"}}
    )

    # Hi·ªÉn th·ªã ph·∫£n h·ªìi c·ªßa tr·ª£ l√Ω
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = result["output"]
        message_placeholder.markdown(full_response + "|")
    message_placeholder.markdown(full_response)
    st.session_state.messages.append({"role": "assistant", "content": full_response})
